{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Data Science in Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://cdn.oreillystatic.com/oreilly/booksamplers/9781449367619_sampler.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "* [TED Talks](https://www.ted.com/talks) for examples of 10 minutes talks.\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in Jupyter Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: pick a data science problem that you plan to solve using Twitter Data\n",
    "* The problem should be important and interesting, which has a potential impact in some area.\n",
    "* The problem should be solvable using twitter data and data science solutions.\n",
    "\n",
    "Please briefly describe in the following cell: what problem are you trying to solve? why this problem is important and interesting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We are looking at the trending hashtags and finding out the emotional responses people have in various regions due to \n",
    "those hashtags. We can categorize regions of the country by the emotional words used in tweets. This problem is interesting\n",
    "because you can find out how regions feel about specific issues and trends by the way people react to them on twitter. This is\n",
    "important because the data could be used by companies for advertising or politicians to find out how people feel about certain social\n",
    "issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection: Download Twitter Data using API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to solve the above problem, you need to collect some twitter data. You could select a topic that is relevant to your problem, and use Twitter API to download the relevant tweets. It is recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter, json, operator, sys\n",
    "import collections\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'htBMGArjlGDW8FXLlb9iuXHW4'\n",
    "    CONSUMER_SECRET ='udmNO1AFXMi1B5ZEmlmn0jY8oudyKkinXsa3ZpjzfMUwP0Txqj'\n",
    "    OAUTH_TOKEN = '361006898-N3gjDZDTEvM6s4SQPNZGuJJN1e7HSGcnuHKr578l'\n",
    "    OAUTH_TOKEN_SECRET = '0BNDtw48dwzu3PyWRd0zh2jMP977xGIy05rIQ1GAbQNJt'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "twitter_api = oauth_login()\n",
    "query = 'Mass Effect' #Popular right now\n",
    "question = {}\n",
    "counter1 = 0\n",
    "lowestID = 0\n",
    "#<insert your code here>\n",
    "#   Please add comments to explain the general idea of each block of the code.\n",
    "for i in range (1, 3):\n",
    "    if i == 1:\n",
    "        tempQuestion = twitter_api.search.tweets(q=query, count=100)\n",
    "    else:\n",
    "        tempQuestion = twitter_api.search.tweets(q=query, count=100, max_id=lowestID)\n",
    "    #didn't quite get this to build properly, got 100 tweets\n",
    "    question = dict(question.items() + tempQuestion.items())\n",
    "    for result in question[\"statuses\"]:\n",
    "        if result['id'] < lowestID or lowestID == 0:\n",
    "            lowestID = result['id']\n",
    "\n",
    "for result in question[\"statuses\"]:\n",
    "     counter1 += 1\n",
    "     # print \"(%s) @%s %s\" % (result[\"created_at\"], result[\"user\"][\"screen_name\"], result[\"text\"])\n",
    "\n",
    "\n",
    "json_file_name = 'Results.json'\n",
    "#---------\n",
    "list_tweets = question\n",
    "print list_tweets\n",
    "\n",
    "#------------\n",
    "\n",
    "with open(json_file_name, 'w') as outfile: #output the JSON in a dump, just the statuses\n",
    "    json.dump(list_tweets[\"statuses\"], outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report  statistics about the tweets you collected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The total number of tweets collected:  < INSERT THE NUMBER HERE>\n",
    "#<insert your code here>\n",
    "number_tweets = counter1\n",
    "print number_tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration: Exploring the Tweets and Tweet Entities\n",
    "\n",
    "**(1) Word Count:** \n",
    "* Load the tweets you collected in the local file (txt or json)\n",
    "* compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 most-frequent words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "import json, operator\n",
    "json_file_name = 'Results.json'\n",
    "#--------\n",
    "result = []\n",
    "new_list_of_tweets = json.loads(open(json_file_name, \"r\").read())\n",
    "#Read in the file\n",
    "wordDict = dict();\n",
    "for i in range (0, counter1):\n",
    "    # print new_list_of_tweets[i]\n",
    "    tempList = new_list_of_tweets[i][\"text\"].lower().split()\n",
    "    for word in tempList:\n",
    "        if word in wordDict:\n",
    "            wordDict[word] += 1\n",
    "        else:\n",
    "            wordDict[word] = 1\n",
    "\n",
    "import operator\n",
    "sorted_wordDict = list(reversed(sorted(wordDict.items(), key=operator.itemgetter(1))))\n",
    "tempCounter = 0\n",
    "while tempCounter < 30:\n",
    "    print str(sorted_wordDict[tempCounter][0]) + \": \" + str(sorted_wordDict[tempCounter][1])\n",
    "    tempCounter += 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (2) Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 most-retweeted tweets in your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "Associations = dict()\n",
    "for i in range (0, counter1):\n",
    "    Associations[new_list_of_tweets[i][\"text\"]] = new_list_of_tweets[i][\"retweet_count\"]\n",
    "\n",
    "sorted_Associations = list(reversed(sorted(Associations.items(), key=operator.itemgetter(1))))\n",
    "tempCounter = 0\n",
    "while tempCounter < 10:\n",
    "    print sorted_Associations[tempCounter][0].encode('utf-8').strip() + \": \" + str(sorted_Associations[tempCounter][1])\n",
    "    tempCounter += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot the top 10 most-frequent hashtags and top 10 most-mentioned users in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hashtags = dict()\n",
    "mentioned_users = dict()\n",
    "\n",
    "# Iterate through tweets\n",
    "for i in range (0, number_tweets):\n",
    "    # Get hashtags entity\n",
    "    curr_hashtags = new_list_of_tweets[i][\"entities\"][\"hashtags\"]\n",
    "    \n",
    "    # Get mentions entity\n",
    "    curr_mentions = new_list_of_tweets[i][\"entities\"][\"user_mentions\"]    \n",
    "    \n",
    "    # Get hashtag counts\n",
    "    for j in range(0, len(curr_hashtags)):\n",
    "        hashtag_text = curr_hashtags[j][\"text\"]\n",
    "        if hashtag_text in hashtags:\n",
    "            hashtags[hashtag_text] += 1\n",
    "        else:\n",
    "            hashtags[hashtag_text] = 1\n",
    "            \n",
    "    # Get mentions counts\n",
    "    for j in range(0, len(curr_mentions)):\n",
    "        mention_text = curr_mentions[j][\"screen_name\"]\n",
    "        if mention_text in mentioned_users:\n",
    "            mentioned_users[mention_text] += 1\n",
    "        else:\n",
    "            mentioned_users[mention_text] = 1\n",
    "\n",
    "# Sort entities\n",
    "sorted_hashtags = list(reversed(sorted(hashtags.items(), key=operator.itemgetter(1))))\n",
    "sorted_mentioned_users = list(reversed(sorted(mentioned_users.items(), key=operator.itemgetter(1))))\n",
    "\n",
    "# Get min of entity count and 10\n",
    "hashtag_item_count = len(sorted_hashtags) if len(sorted_hashtags) < 10 else 10\n",
    "mentioned_users_item_count = len(sorted_mentioned_users) if len(sorted_mentioned_users) < 10 else 10\n",
    "\n",
    "# Print tables\n",
    "print '{}{}{}'.format('Most Common Hashtags', '\\n', '-----------------------------')\n",
    "for i in range(0, hashtag_item_count):\n",
    "    print '{}: {}'.format(sorted_hashtags[i][0], sorted_hashtags[i][1])\n",
    "    \n",
    "print '{}{}{}{}'.format('\\n', 'Most Common User Mentions', '\\n', '-----------------------------')\n",
    "for i in range(0, mentioned_users_item_count):\n",
    "    print '{}: {}'.format(sorted_mentioned_users[i][0], sorted_mentioned_users[i][1])\n",
    "\n",
    "# Graphs\n",
    "hashtags_texts = [hash[0] for hash in sorted_hashtags[0:10]]\n",
    "hashtags_counts = [hash[1] for hash in sorted_hashtags[0:10]]\n",
    "\n",
    "hashtags_len = range(len(hashtags_texts))\n",
    "plt.bar(hashtags_len, hashtags_counts, align='center')\n",
    "locs, labels = plt.xticks(hashtags_len, hashtags_texts)\n",
    "plt.setp(labels, rotation=90)\n",
    "plt.show()\n",
    "\n",
    "user_mention_texts = [hash[0] for hash in sorted_mentioned_users[0:10]]\n",
    "user_mention_counts = [hash[1] for hash in sorted_mentioned_users[0:10]]\n",
    "\n",
    "user_mention_len = range(len(user_mention_texts))\n",
    "plt.bar(user_mention_len, user_mention_counts, align='center')\n",
    "locs, labels = plt.xticks(user_mention_len, user_mention_texts)\n",
    "plt.setp(labels, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the number of user mentions in the list using the following bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "bins_dict = dict()\n",
    "\n",
    "# Initialize bins\n",
    "for bin in bins:\n",
    "    bins_dict[bin] = 0\n",
    "\n",
    "# Put values in bins\n",
    "for user in sorted_mentioned_users:\n",
    "    count = user[1]\n",
    "    bin_count = (count / 10) * 10\n",
    "    \n",
    "    bins_dict[bin_count] += 1\n",
    "\n",
    "# Sort bins\n",
    "sorted_bins = list(reversed(sorted(bins_dict.items(), key=operator.itemgetter(1))))\n",
    "\n",
    "# Graph histogram\n",
    "bin_ids = [bin[0] for bin in sorted_bins]\n",
    "bin_vals = [bin[1] for bin in sorted_bins]\n",
    "\n",
    "bins_len = range(len(bin_ids))\n",
    "plt.bar(bins_len, bin_vals, align='center')\n",
    "locs, labels = plt.xticks(bins_len, bin_ids)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ** (4) Getting \"All\" friends and \"All\" followers of a popular user in the tweets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers in your collection of tweets.\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Solution: implement a data science solution to the problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly describe the idea of your solution to the problem in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write codes to implement the solution in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: summarize and visualize the results discovered from the analysis\n",
    "\n",
    "Please use figures, tables, or videos to communicate the results with the audience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this Jupyter notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"jupyter notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . Each team present their case studies in class for 10 minutes.\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through Canvas, in the Assignment \"Case Study 1\".\n",
    "        \n",
    "** Note: Each team only needs to submit one submission in Canvas **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Peer-Review Grading Template:\n",
    "\n",
    "** Total Points: (100 points) ** Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
    "\n",
    "Please add an \"**X**\" mark in front of your rating: \n",
    "\n",
    "For example:\n",
    "\n",
    "*2: bad*\n",
    "          \n",
    "**X** *3: good*\n",
    "    \n",
    "*4: perfect*\n",
    "\n",
    "\n",
    "    ---------------------------------\n",
    "    The Problem: \n",
    "    ---------------------------------\n",
    "    \n",
    "    1. (5 points) how well did the team describe the problem they are trying to solve using twitter data? \n",
    "       0: not clear\n",
    "       1: I can barely understand the problem\n",
    "       2: okay, can be improved\n",
    "       3: good, but can be improved\n",
    "       4: very good\n",
    "       5: crystal clear\n",
    "    \n",
    "    2. (10 points) do you think the problem is important or has a potential impact?\n",
    "        0: not important at all\n",
    "        2: not sure if it is important\n",
    "        4: seems important, but not clear\n",
    "        6: interesting problem\n",
    "        8: an important problem, which I want to know the answer myself\n",
    "       10: very important, I would be happy invest money on a project like this.\n",
    "    \n",
    "    ----------------------------------\n",
    "    Data Collection:\n",
    "    ----------------------------------\n",
    "    \n",
    "    3. (10 points) Do you think the data collected are relevant and sufficient for solving the above problem? \n",
    "       0: not clear\n",
    "       2: I can barely understand what data they are trying to collect\n",
    "       4: I can barely understand why the data is relevant to the problem\n",
    "       6: the data are relevant to the problem, but better data can be collected\n",
    "       8: the data collected are relevant and at a proper scale (> 300 tweets)\n",
    "      10: the data are properly collected and they are sufficient\n",
    "\n",
    "    -----------------------------------\n",
    "    Data Exploration:\n",
    "    -----------------------------------\n",
    "    4. How well did the team solve the following task:\n",
    "    (1) Word Count (5 points):\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "    \n",
    "    (2) Find the most popular tweets in your collection of tweets: (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "    \n",
    "    (3) Find popular twitter entities  (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "\n",
    "    (4) Find user's followers and friends (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "\n",
    "    -----------------------------------\n",
    "    The Solution\n",
    "    -----------------------------------\n",
    "    5.  how well did the team describe the solution they used to solve the problem? \n",
    "       0: not clear\n",
    "       2: I can barely understand\n",
    "       4: okay, can be improved\n",
    "       6: good, but can be improved\n",
    "       8: very good\n",
    "       10: crystal clear\n",
    "       \n",
    "    6. how well is the solution in solving the problem? \n",
    "       0: not relevant\n",
    "       1: barely relevant to the problem\n",
    "       2: okay solution, but there is an easier solution.\n",
    "       3: good, but can be improved\n",
    "       4: very good, but solution is simple/old\n",
    "       5: innovative and technically sound\n",
    "       \n",
    "    7. how well did the team implement the solution in python? \n",
    "       0: the code is not relevant to the solution proposed\n",
    "       2: the code is barely understandable, but not relevant\n",
    "       4: okay, the code is clear but incorrect\n",
    "       6: good, the code is correct, but with major errors\n",
    "       8: very good, the code is correct, but with minor errors\n",
    "      10: perfect \n",
    "   \n",
    "    -----------------------------------\n",
    "    The Results\n",
    "    -----------------------------------\n",
    "     8.  How well did the team present the results they found in the data? \n",
    "       0: not clear\n",
    "       2: I can barely understand\n",
    "       4: okay, can be improved\n",
    "       6: good, but can be improved\n",
    "       8: very good\n",
    "      10: crystal clear\n",
    "       \n",
    "     9.  How do you think the results they found in the data? \n",
    "       0: not clear\n",
    "       1: likely to be wrong\n",
    "       2: okay, maybe wrong\n",
    "       3: good, but can be improved\n",
    "       4: make sense, but not interesting\n",
    "       5: make sense and very interesting\n",
    "     \n",
    "    -----------------------------------\n",
    "    The Presentation\n",
    "    -----------------------------------\n",
    "    10. How all the different parts (data, problem, solution, result) fit together as a coherent story?  \n",
    "       0: they are irrelevant\n",
    "       1: I can barely understand how they are related to each other\n",
    "       2: okay, the problem is good, but the solution doesn't match well, or the problem is not solvable.\n",
    "       3: good, but the results don't make much sense in the context\n",
    "       4: very good fit, but not exciting (the storyline can be improved/polished)\n",
    "       5: a perfect story\n",
    "      \n",
    "    11. Did the presenter make good use of the 10 minutes for presentation?  \n",
    "       0: the team didn't present\n",
    "       1: bad, barely finished a small part of the talk\n",
    "       2: okay, barely finished most parts of the talk.\n",
    "       3: good, finished all parts of the talk, but some part is rushed\n",
    "       4: very good, but the allocation of time on different parts can be improved.\n",
    "       5: perfect timing and good use of time      \n",
    "\n",
    "    12. How well do you think of the presentation (overall quality)?  \n",
    "       0: the team didn't present\n",
    "       1: bad\n",
    "       2: okay\n",
    "       3: good\n",
    "       4: very good\n",
    "       5: perfect\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Overall: \n",
    "    -----------------------------------\n",
    "    13. How many points out of the 100 do you give to this project in total?  Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
    "    Total score:\n",
    "    \n",
    "    14. What are the strengths of this project? Briefly, list up to 3 strengths.\n",
    "       1: \n",
    "       2:\n",
    "       3:\n",
    "    \n",
    "    15. What are the weaknesses of this project? Briefly, list up to 3 weaknesses.\n",
    "       1:\n",
    "       2:\n",
    "       3:\n",
    "    \n",
    "    16. Detailed comments and suggestions. What suggestions do you have for this project to improve its quality further.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ---------------------------------\n",
    "    Your Vote: \n",
    "    ---------------------------------\n",
    "    1. [Overall Quality] Between the two submissions that you are reviewing, which team would you vote for a better score?  \n",
    "       -1: I vote the other team is better than this team\n",
    "        0: the same\n",
    "        1: I vote this team is better than the other team \n",
    "        \n",
    "    2. [Presentation] Among all the teams in the presentation, which team do you think deserves the best presentation award for this case study?  \n",
    "        1: Team 1\n",
    "        2: Team 2\n",
    "        3: Team 3\n",
    "        4: Team 4\n",
    "        5: Team 5\n",
    "        6: Team 6\n",
    "        7: Team 7\n",
    "        8: Team 8\n",
    "        9: Team 9\n",
    "       10: Team 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
